{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591f45a2",
   "metadata": {},
   "source": [
    "Módulo 3 - Regressão\n",
    "========================================================\n",
    "\n",
    "Professor: Marcos Cesar Gritti  \n",
    "Email: cesargritti@gmail.com\n",
    "\n",
    "Antes de começar:\n",
    " - Crie uma cópia deste notebook, e o renomeie para \"aula_1_modulo_3_{seu_nome}\";\n",
    " - Caso seu ambiente Anaconda não possua uma das dependências necessárias para a execução do código contigo neste notebook, abra uma célula e execute o comando: ```!pip install -r ../requirements.txt```\n",
    "\n",
    "Neste módulo vamos aprender sobre:\n",
    " 1. **Seleção/organização de features (variáveis de entrada)**;\n",
    " 1. **Particionamento de dados (Conjunto de treinamento e de validação)**;\n",
    " 2. **Regressão usando Regressão Linear Multipla e Random Forest**;\n",
    " \n",
    "A aula de hoje será um exercício de avaliação, que deverá ser entregue no **Google Classroom**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c0cbe6",
   "metadata": {},
   "source": [
    "Carregando os dados do exercício de hoje\n",
    "===================================\n",
    "\n",
    "Os dados que utilizaremos na aula de hoje estão salvos no arquivo `dados_tratados.csv`. <br></br>\n",
    "\n",
    "**Exercício**: Carregue-os em memória em uma variável chamada `dados`, na célula abaixo, utilizando a biblioteca ``pandas``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515a55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014b540",
   "metadata": {},
   "source": [
    "1 - Seleção/organização de features (variáveis de entrada)\n",
    "===============================================\n",
    "\n",
    "São poucos os algorítmos de **Machine Learning** que conseguem lidar com variáveis categóricas sem um devido pré-processamento. Por esse motivo, é importante codificá-las de forma adequada, para que seja possível comparar técnicas resultados de técnicas distintas, mesmo que uma delas não trate valores categóricos internamente.\n",
    "\n",
    "Os métodos mais utilizados para codificação de variáveis categóricas são:\n",
    " - **One hot encoding**: Criar uma coluna para cada possível valor de saída de sua variável categórica. Quando a sua amostra pertence à **classe** representada por uma determinada coluna, atribuimos o valor 1 (essa amostra percente a esta classe), caso contrário, a célula desta coluna recebe o valor 0 (essa amostra não pertence a esta classe);\n",
    " - **Variáveis Dummy**: Similar a codificação **One hot encoding**, porém, omite uma das possíveis colunas de saída. Por exemplo, se nossa variável categórica \"*Tipo*\" pode assumir os valores A, B e C, criamos apenas duas colunas, denominadas *Tipo_A* e *Tipo_B*. Note que, na ausência das duas (valor = 0), sabemos que estamos nos referindo a uma amostra do *Tipo_C*.\n",
    " \n",
    "**Exercício**: Codifique as variáveis categóricas (**localidade** e **tipo**) do conjunto de dados, e salve o\n",
    "resultado em um variável chamada ``dataset``, contendo apenas as **features** (variáveis de entrada) e o **target** (valor do imóvel, variável **preco**) que utilizaremos na análise de regressão.\n",
    "\n",
    "**Dicas**:\n",
    " - Ao menos que você tenha projetado uma camada de **Imputação de Dados** para o seu problema, lembre-se de remover dados nulos do seu conjunto antes de organizar as suas **features**;\n",
    " - Procure pela documentação da função ``get_dummies`` da biblioteca ``pandas``;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a988908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966142bf",
   "metadata": {},
   "source": [
    "2 - Particionamento de dados\n",
    "========================\n",
    "\n",
    "Particionar dados significa dividí-los em conjuntos de amostras para fins distintos. Em **Data Mining** e **Machine Learning**, é importante segregar os dados em um conjunto de **treinamento** e um conjunto de **teste**.\n",
    "\n",
    "**Por que?**\n",
    "\n",
    "Precisamos separar alguns dados para teste para que possamos verificar a qualidade da solução de forma justa, ou seja, em um conjunto de dados não visto previamente pelo algorítmo no momento de treinamento do modelo. Essa técnica recebe o nome de **Validação Cruzada** (*Cross Validation*). Existem várias formas de aplicar a **Validação Cruzada**:\n",
    " - Segregação em **Treinamento** e **Teste**;\n",
    " - Segregação em **Treinamento** e **Teste** com estratificação;\n",
    " - Segregação em **Treinamento**, **Teste** e validação;\n",
    " - KFolds (Vários conjuntos de **Treinamento** e **Teste** para otimização de hiperparâmetros);\n",
    " - Entre outras técnicas utilizadas, por exemplo, em dados que dependem do tempo (Séries temporais);\n",
    " \n",
    "Neste exercício, vamos segregar os dados em: um conjunto de **treinamento**; e um conjunto de **teste**.\n",
    "\n",
    "Particione os dados de entrada $X$ e saída $y$ da etapa anterior para que possamos dar continuidade na\n",
    "análise de regressão. Para isso, crie/utiliza as células que estão entre essa seção (2) e a próxima.\n",
    "Os conjuntos de treinamento e de teste devem ser salvos, respectivamente, em variáveis chamadas\n",
    "`X_train`, `y_train`, `X_test` e `y_test`.\n",
    "\n",
    "**Dica**: Procure pela documentação da função `train_test_split`, pertencente ao pacote `model_selection` da biblioteca `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b836248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26863a06",
   "metadata": {},
   "source": [
    "3 - Regressão usando Regressão Linear Multipla e Random Forest\n",
    "======================================================\n",
    "\n",
    "Agora que temos dados particionados, podemos iniciar a modelagem.\n",
    "\n",
    "**Exercício**: Crie dois modelos de regressão (Regressão Linear Multipla e Random Forest) utilizando os\n",
    "dados de **treinamento**. Apresente os resultados obtidos (para cada modelo) no conjunto de **test** para o professor ulizando a métrica MAPE (*Mean Absolute Percentage Error*), descrita pela seguinte fórmula:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{MAPE} = \\frac{1}{N} \\sum\\limits_{i=1}^N \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right|\n",
    "\\end{equation}\n",
    "\n",
    "Por fim, crie uma cópia do **dataframe** inicial (``dados``), e adicione a ele as seguintes colunas:\n",
    " - pred_lm: A previsão do valor do imóvel (Modelo Linear);\n",
    " - erro_lm: O erro de nossa predição (Modelo Linear);\n",
    " - ape_lm: O erro percentual de nossa predição (Modelo Linear);\n",
    " - pred_rf: A previsão do valor do imóvel (Random Forest);\n",
    " - erro_rf: O erro de nossa predição (Random Forest);\n",
    " - ape_rf: O erro percentual de nossa predição (Random Forest);\n",
    " \n",
    "**Dicas**: Procure pelas seguintes documentações da biblioteca `sklearn`:\n",
    "- classe `LinearRegression` percentente ao pacote `linear_model`;\n",
    "- classe `RandomForestRegression` pertencente ao pacote `ensemble`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbc62b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mape(y, yp): ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
